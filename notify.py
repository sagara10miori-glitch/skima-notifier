import requests
from bs4 import BeautifulSoup
import json
import os
import time
from datetime import datetime

WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK")

HEADERS = {
    "User-Agent": "SKIMA-Notifier/1.0 (+GitHub Actions; contact: example@example.com)"
}

ORANGE = 0xFFA500  # Embed ã®è‰²ï¼ˆã‚ªãƒ¬ãƒ³ã‚¸ï¼‰
OPT_URL = "https://skima.jp/dl/search?cg=60"  # opt è²©å£²ä¸€è¦§


def is_quiet_hours():
    """0:30ã€œ7:30 ã®é–“ã¯ True"""
    now = datetime.now()
    h, m = now.hour, now.minute
    return (
        (h == 0 and m >= 30) or
        (1 <= h <= 6) or
        (h == 7 and m < 30)
    )


def fetch_html(url, retries=2, delay=2):
    for attempt in range(retries + 1):
        try:
            response = requests.get(url, headers=HEADERS, timeout=10)
            if response.status_code == 200:
                return response.text
        except Exception:
            pass
        if attempt < retries:
            time.sleep(delay)
    return None


def parse_item(card):
    title_tag = card.select_one(".details h5 a")
    title = title_tag.text.strip() if title_tag else "ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜Ž"

    author_tag = card.select_one(".details .username")
    author = author_tag.text.strip() if author_tag else "ä½œè€…ä¸æ˜Ž"

    img_tag = card.select_one(".image img")
    image = img_tag["src"] if img_tag else None

    price_tag = card.select_one(".price")
    price_raw = price_tag.text.strip() if price_tag else None

    # ---- ä¾¡æ ¼ã‚’ã€Œâ—¯â—¯å††ã€å½¢å¼ã«çµ±ä¸€ã—ã€æ•°å€¤ã‚‚ä¿æŒ ----
    if price_raw:
        digits = "".join(c for c in price_raw if c.isdigit())
        price_value = int(digits) if digits else None
        price = f"{price_value:,}å††" if price_value is not None else price_raw
    else:
        price_value = None
        price = "ä¾¡æ ¼ä¸æ˜Ž"

    link_tag = card.select_one(".image a")
    url = "https://skima.jp" + link_tag["href"] if link_tag else None

    return {
        "title": title,
        "author": author,
        "image": image,
        "price": price,
        "price_value": price_value,
        "url": url
    }


def get_items_from_user(user_id):
    url = f"https://skima.jp/profile?id={user_id}"
    html = fetch_html(url)
    if html is None:
        return []

    soup = BeautifulSoup(html, "html.parser")
    items = []

    for card in soup.select(".inner"):
        link_tag = card.select_one(".image a")
        if not link_tag:
            continue

        if "/dl/detail" not in link_tag.get("href", ""):
            continue

        items.append(parse_item(card))

    return items


def get_opt_items():
    html = fetch_html(OPT_URL)
    if html is None:
        return []

    soup = BeautifulSoup(html, "html.parser")
    items = []

    for card in soup.select(".inner"):
        items.append(parse_item(card))

    return items


def send_batch_notification(user_new, opt_new):
    """users.txt â†’ ã‚¿ã‚¤ãƒˆãƒ« â†’ opt ã®é †ã§ã¾ã¨ã‚ã¦é€šçŸ¥"""

    if not user_new and not opt_new:
        return

    # --- content ã®çµ„ã¿ç«‹ã¦ ---
    lines = []

    # @everyoneï¼ˆé™ã‹ãªæ™‚é–“å¸¯ã¯å¤–ã™ï¼‰
    if not is_quiet_hours():
        lines.append("@everyone")

    # users æ–°ç€ãŒã‚ã‚‹å ´åˆã¯ä½•ã‚‚æŒŸã¾ãªã„ï¼ˆãã®ã¾ã¾ Embed ãŒä¸¦ã¶ï¼‰
    # opt æ–°ç€ãŒã‚ã‚‹å ´åˆã¯ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŒ¿å…¥
    if opt_new:
        lines.append("ðŸ“˜ OPTè²©å£²ï¼ˆ8000å††ä»¥ä¸‹ï¼‰")

    content = "\n".join(lines)

    # --- Embed ã®ä½œæˆ ---
    embeds = []

    # â‘  users æ–°ç€ï¼ˆå…ˆã«ä¸¦ã¹ã‚‹ï¼‰
    for item in user_new:
        embeds.append({
            "title": item["title"],
            "url": item["url"],
            "color": ORANGE,
            "image": {"url": item["image"]},
            "description": (
                f"**ä¾¡æ ¼ï¼š{item['price']}**\n"
                f"**ä½œè€…ï¼š{item['author']}**\n"
                f"**[å•†å“ãƒšãƒ¼ã‚¸ã¯ã“ã¡ã‚‰]({item['url']})**"
            )
        })

    # â‘¡ opt æ–°ç€ï¼ˆå¾Œã«ä¸¦ã¹ã‚‹ï¼‰
    for item in opt_new:
        embeds.append({
            "title": item["title"],
            "url": item["url"],
            "color": ORANGE,
            "image": {"url": item["image"]},
            "description": (
                f"**ä¾¡æ ¼ï¼š{item['price']}**\n"
                f"**ä½œè€…ï¼š{item['author']}**\n"
                f"**[å•†å“ãƒšãƒ¼ã‚¸ã¯ã“ã¡ã‚‰]({item['url']})**"
            )
        })

    # --- Discord ã«é€ä¿¡ ---
    requests.post(WEBHOOK_URL, json={"content": content, "embeds": embeds})


def main():
    # --- å‰å›žãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ---
    if os.path.exists("last_data.json"):
        with open("last_data.json", "r", encoding="utf-8") as f:
            last_data = json.load(f)
    else:
        last_data = {"users": {}, "opt": []}

    # --- users.txt ã®å·¡å›ž ---
    with open("users.txt", "r", encoding="utf-8") as f:
        user_ids = [line.strip() for line in f]

    new_last_users = {}
    user_new_items = []

    for uid in user_ids:
        time.sleep(1)
        items = get_items_from_user(uid)
        new_last_users[uid] = items

        old_urls = {item["url"] for item in last_data.get("users", {}).get(uid, [])}
        for item in items:
            if item["url"] not in old_urls:
                user_new_items.append(item)

    # --- opt è²©å£²ã®å·¡å›ž ---
    opt_items = get_opt_items()
    old_opt_urls = {item["url"] for item in last_data.get("opt", [])}

    opt_new_items = []
    for item in opt_items:
        if item["url"] not in old_opt_urls:
            if item["price_value"] is not None and item["price_value"] <= 8000:
                opt_new_items.append(item)

    # opt ã¯ä¾¡æ ¼ã®å®‰ã„é †
    opt_new_items.sort(key=lambda x: x["price_value"] or 999999)

    # --- é€šçŸ¥ ---
    send_batch_notification(user_new_items, opt_new_items)

    # --- ãƒ‡ãƒ¼ã‚¿ä¿å­˜ ---
    new_last_data = {
        "users": new_last_users,
        "opt": opt_items
    }

    with open("last_data.json", "w", encoding="utf-8") as f:
        json.dump(new_last_data, f, ensure_ascii=False, indent=2)


if __name__ == "__main__":
    main()
