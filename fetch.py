import cloudscraper
from bs4 import BeautifulSoup
import re
import time

# cloudscraper ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½¿ã„å›ã™ï¼ˆé«˜é€ŸåŒ–ï¼‰
session = cloudscraper.create_scraper()


def fetch_items(priority_only=False):
    """
    SKIMA ã®æ–°ç€ä¸€è¦§ã‚’å–å¾—ã—ã¦ item dict ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™ã€‚
    priority_only=True ã®å ´åˆã¯ã€Œç‰¹é¸ã€ã€ŒãŠã™ã™ã‚ã€ã®ã¿æŠ½å‡ºã€‚
    """

    url = "https://skima.jp/item-list"

    # --- ãƒªãƒˆãƒ©ã‚¤ä»˜ãã§ HTML ã‚’å–å¾— ---
    for attempt in range(3):
        try:
            html = session.get(url, timeout=10).text
            break
        except Exception:
            time.sleep(1.5 * (attempt + 1))
    else:
        return []

    soup = BeautifulSoup(html, "lxml")

    items = []

    # SKIMA ã®ã‚«ãƒ¼ãƒ‰æ§‹é€ ã«å¯¾å¿œ
    for card in soup.select(".item-card"):
        try:
            # --- ID ---
            item_id = card.get("data-id")

            # --- ã‚¿ã‚¤ãƒˆãƒ« ---
            title_tag = card.select_one(".item-title")
            title = title_tag.get_text(strip=True) if title_tag else "ä¸æ˜"

            # --- ä¾¡æ ¼ ---
            price_tag = card.select_one(".item-price")
            price_text = price_tag.get_text(strip=True) if price_tag else "0"
            price = int(re.sub(r"\D", "", price_text))

            # --- ä½œè€…å & ä½œè€…ID ---
            author_tag = card.select_one(".ellipsis.username a")
            author_name = author_tag.get_text(strip=True) if author_tag else "ä¸æ˜"

            author_id = None
            if author_tag:
                href = author_tag.get("href", "")
                if "id=" in href:
                    author_id = href.split("id=")[-1]

            # --- ãƒ©ãƒ³ã‚¯ï¼ˆğŸ”¥ç‰¹é¸ / âœ¨ãŠã™ã™ã‚ / é€šå¸¸ï¼‰ ---
            rank_tag = card.select_one(".item-rank")
            rank = rank_tag.get_text(strip=True) if rank_tag else "é€šå¸¸"

            # --- ç”»åƒ ---
            img_tag = card.select_one("img")
            image = img_tag.get("src") if img_tag else None

            # --- URL ---
            link_tag = card.select_one("a")
            url = "https://skima.jp" + link_tag.get("href") if link_tag else ""

            # --- æ·±å¤œå¸¯ã® priority_only ãƒ•ã‚£ãƒ«ã‚¿ ---
            if priority_only and rank not in ["ğŸ”¥ç‰¹é¸", "âœ¨ãŠã™ã™ã‚"]:
                continue

            items.append({
                "id": item_id,
                "title": title,
                "price": price,
                "author_id": author_id,
                "author_name": author_name,
                "rank": rank,
                "image": image,
                "url": url
            })

        except Exception:
            # HTML å¤‰æ›´ãªã©ã§ä¸€éƒ¨å£Šã‚Œã¦ã„ã¦ã‚‚è½ã¨ã•ãªã„
            continue

    return items
