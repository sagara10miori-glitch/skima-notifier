import requests
from bs4 import BeautifulSoup
import re
import time

URL = "https://skima.jp/dl/search"

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/120.0.0.0 Safari/537.36"
    ),
    "Accept-Language": "ja,en-US;q=0.9,en;q=0.8",
}


def fetch_items(priority_only=False):
    html = None

    # Cloudflare ã«å„ªã—ã„æ§ãˆã‚ãªãƒªãƒˆãƒ©ã‚¤
    for attempt in range(2):
        try:
            r = requests.get(URL, headers=HEADERS, timeout=10)
            if r.status_code == 200:
                html = r.text
                break

            print(f"[WARN] fetch status={r.status_code}")
            time.sleep(2 + attempt)

        except Exception as e:
            print(f"[WARN] fetch exception: {e}")
            time.sleep(2)

    if not html:
        print("[WARN] failed to fetch item-list")
        return []

    soup = BeautifulSoup(html, "lxml")
    items = []

    # æ–° UI ã®å•†å“ã‚«ãƒ¼ãƒ‰ã¯ <li> å†…ã« <div class="inner">
    for li in soup.select("li"):
        inner = li.select_one(".inner")
        if not inner:
            continue

        # ç”»åƒ
        img_tag = inner.select_one(".image img")
        image = img_tag.get("src") if img_tag else None

        # ä¾¡æ ¼
        price_tag = inner.select_one(".price")
        price_text = price_tag.get_text(strip=True) if price_tag else "0"
        price = int(re.sub(r"\D", "", price_text) or 0)

        # ã‚¿ã‚¤ãƒˆãƒ«
        title_tag = inner.select_one("h5 a")
        title = title_tag.get_text(strip=True) if title_tag else "ä¸æ˜"

        # URL
        url = "https://skima.jp" + title_tag.get("href") if title_tag else ""

        # IDï¼ˆdetail?id=xxxx ã‹ã‚‰æŠ½å‡ºï¼‰
        item_id = None
        if url and "id=" in url:
            item_id = url.split("id=")[-1]

        # ä½œè€…ï¼ˆclass ãŒå¤‰ã‚ã£ã¦ã‚‚ç¢ºå®Ÿã«æ‹¾ãˆã‚‹ï¼‰
        author_tag = inner.select_one("a[href*='profile']")
        author_name = author_tag.get_text(strip=True) if author_tag else "ä¸æ˜"

        author_id = None
        if author_tag:
            href = author_tag.get("href") or ""
            if "id=" in href:
                author_id = href.split("id=")[-1]

        # rankï¼ˆæ–° UI ã§ã¯æ¶ˆãˆãŸã®ã§ã‚¿ã‚¤ãƒˆãƒ«ã®çµµæ–‡å­—ã§åˆ¤å®šï¼‰
        if "ğŸ”¥" in title:
            rank = "ğŸ”¥ç‰¹é¸"
        elif "âœ¨" in title:
            rank = "âœ¨ãŠã™ã™ã‚"
        else:
            rank = "é€šå¸¸"

        # æ·±å¤œå¸¯ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆå„ªå…ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã¿é€šçŸ¥ï¼‰
        if priority_only and rank not in ("ğŸ”¥ç‰¹é¸", "âœ¨ãŠã™ã™ã‚"):
            continue

        items.append({
            "id": item_id,
            "title": title,
            "price": price,
            "author_id": author_id,
            "author_name": author_name,
            "rank": rank,
            "image": image,
            "url": url,
        })

    print(f"[INFO] fetch_items: {len(items)} items (priority_only={priority_only})")
    return items
